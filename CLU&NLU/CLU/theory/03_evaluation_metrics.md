# CLU Theory: Evaluation Metrics

Evaluating CLU models is essential for building robust conversational systems. Common metrics include:

- **Intent Accuracy:** Percentage of correct intent predictions
- **Entity F1 Score:** Harmonic mean of precision and recall for entity extraction
- **Slot Filling Accuracy:** Percentage of conversations where all required slots are filled correctly
- **Dialogue Success Rate:** Percentage of conversations that reach a successful outcome

## Example
If your model predicts the correct intent for 90 out of 100 utterances, intent accuracy is 90%.

For more, see [Microsoft CLU Evaluation](https://learn.microsoft.com/en-us/azure/ai-services/language-service/conversational-language-understanding/how-to-evaluate).
