{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2f01317",
   "metadata": {},
   "source": [
    "\n",
    "# Prompt Engineering: Zero-shot, Few-shot, Chain-of-Thought, ReAct, RAG, and Reflexion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3acab94",
   "metadata": {},
   "source": [
    "This notebook demonstrates the latest prompt engineering techniques using the OpenAI API: zero-shot, few-shot, chain-of-thought, ReAct, Retrieval Augmented Generation (RAG), and Reflexion prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d4661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install OpenAI if not already installed\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c6a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "openai.api_key = \"YOUR_API_KEY\"  # Replace with your OpenAI API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d3349",
   "metadata": {},
   "source": [
    "## 1. Zero-shot Prompting\n",
    "Ask the model to perform a task without providing any examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f03bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Translate the following English text to French: 'How are you today?'\"\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=prompt,\n",
    "    max_tokens=60\n",
    ")\n",
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a084a9ec",
   "metadata": {},
   "source": [
    "## 2. Few-shot Prompting\n",
    "Provide a few examples to guide the model's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175bc7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = \"\"\"\n",
    "Classify the sentiment of the following sentences as Positive, Negative, or Neutral.\n",
    "\n",
    "Sentence: I love this product!\n",
    "Sentiment: Positive\n",
    "\n",
    "Sentence: This is terrible.\n",
    "Sentiment: Negative\n",
    "\n",
    "Sentence: It's okay, nothing special.\n",
    "Sentiment: Neutral\n",
    "\n",
    "Sentence: I'm so happy with my purchase!\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=few_shot_prompt,\n",
    "    max_tokens=10\n",
    ")\n",
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9d1257",
   "metadata": {},
   "source": [
    "## 3. Chain-of-Thought Prompting\n",
    "Encourage the model to reason step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65f577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_prompt = \"\"\"\n",
    "Q: If there are 3 cars and each car has 4 wheels, how many wheels are there in total?\n",
    "A: There are 3 cars. Each car has 4 wheels. So, 3 x 4 = 12 wheels in total.\n",
    "\n",
    "Q: If there are 5 boxes and each box contains 8 apples, how many apples are there in total?\n",
    "A:\n",
    "\"\"\"\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=cot_prompt,\n",
    "    max_tokens=50\n",
    ")\n",
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdacdc89",
   "metadata": {},
   "source": [
    "## 4. ReAct (Reason + Act) Prompting\n",
    "Combine reasoning and tool-use in a single prompt for agent-like behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c46852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "react_prompt = '''You are an agent that can reason and act. Answer the question step by step, and if you need to use a tool, say \"Action: <tool> <input>\". Otherwise, say \"Final Answer: <answer>\".\n",
    "\n",
    "Question: What is the capital of France?\n",
    "Thought: I need to recall the capital of France.\n",
    "Final Answer: Paris\n",
    "\n",
    "Question: What is 5 multiplied by 7?\n",
    "Thought: I need to calculate 5 * 7.\n",
    "Final Answer: 35\n",
    "\n",
    "Question: Who wrote 'Pride and Prejudice'?\n",
    "Thought:'''\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=react_prompt,\n",
    "    max_tokens=100\n",
    ")\n",
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0d645c",
   "metadata": {},
   "source": [
    "## 5. Retrieval Augmented Generation (RAG)\n",
    "Provide retrieved context to the model for more accurate answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43cf7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Jane Austen was an English novelist known primarily for her six major novels, including 'Pride and Prejudice'.\"\n",
    "question = \"Who wrote 'Pride and Prejudice'?\"\n",
    "rag_prompt = f\"\"\"Use the following context to answer the question.\\n\\nContext: {context}\\n\\nQuestion: {question}\\nAnswer:\"\"\"\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=rag_prompt,\n",
    "    max_tokens=100\n",
    ")\n",
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011c8ef0",
   "metadata": {},
   "source": [
    "## 6. Reflexion Prompting\n",
    "Reflect on and improve the model's previous answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf32015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the capital of Australia?\"\n",
    "initial_answer = \"Sydney\"\n",
    "reflexion_prompt = f\"\"\"Question: {question}\\nInitial Answer: {initial_answer}\\nReflect on the answer above. If it is incorrect or incomplete, provide an improved answer. Otherwise, confirm it is correct.\\nReflection:\"\"\"\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=reflexion_prompt,\n",
    "    max_tokens=100\n",
    ")\n",
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998346a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Try modifying the prompts above and observe how the model's output changes. For more, see the `/theory` and `/examples` directories, and visit [Prompting Guide](https://www.promptingguide.ai/)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
