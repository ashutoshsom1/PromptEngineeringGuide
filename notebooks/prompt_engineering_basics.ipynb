{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2f01317",
   "metadata": {},
   "source": [
    "\n",
    "# Prompt Engineering: Zero-shot, Few-shot, Chain-of-Thought, ReAct, RAG, and Reflexion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3acab94",
   "metadata": {},
   "source": [
    "This notebook demonstrates the latest prompt engineering techniques using the OpenAI API: zero-shot, few-shot, chain-of-thought, ReAct, Retrieval Augmented Generation (RAG), and Reflexion prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d4661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install OpenAI if not already installed\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e3ea036",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_deployment =deployment_name,\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=\"2024-10-21\" \n",
    "    # Use the latest supported API version\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d3349",
   "metadata": {},
   "source": [
    "## 1. Zero-shot Prompting\n",
    "Ask the model to perform a task without providing any examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93aa3b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment vas-tu aujourd'hui ?\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot Prompting using chat API\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,  # Use your deployment name\n",
    "    messages=[\n",
    "        \n",
    "        {\"role\": \"user\", \"content\": \"Translate the following English text to French: 'How are you today?'\"}\n",
    "    ],\n",
    "    max_tokens=60\n",
    ")\n",
    "print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a084a9ec",
   "metadata": {},
   "source": [
    "## 2. Few-shot Prompting\n",
    "Provide a few examples to guide the model's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "175bc7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = \"\"\"\n",
    "Classify the sentiment of the following sentences as Positive, Negative, or Neutral.\n",
    "\n",
    "Sentence: I love this product!\n",
    "Sentiment: Positive\n",
    "\n",
    "Sentence: This is terrible.\n",
    "Sentiment: Negative\n",
    "\n",
    "Sentence: It's okay, nothing special.\n",
    "Sentiment: Neutral\n",
    "\n",
    "Sentence: I'm so happy with my purchase!\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,  # Use your deployment name\n",
    "    messages=[\n",
    "\n",
    "        {\"role\": \"user\", \"content\": few_shot_prompt}\n",
    "    ],\n",
    "    max_tokens=10\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content.strip())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9d1257",
   "metadata": {},
   "source": [
    "## 3. Chain-of-Thought Prompting\n",
    "Encourage the model to reason step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b65f577b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 boxes. Each box contains 8 apples. So, 5 x 8\n"
     ]
    }
   ],
   "source": [
    "cot_prompt = \"\"\"\n",
    "Q: If there are 3 cars and each car has 4 wheels, how many wheels are there in total?\n",
    "A: There are 3 cars. Each car has 4 wheels. So, 3 x 4 = 12 wheels in total.\n",
    "\n",
    "Q: If there are 5 boxes and each box contains 8 apples, how many apples are there in total?\n",
    "A:\n",
    "\"\"\"\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,  # Use your deployment name\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": cot_prompt}\n",
    "    ],\n",
    "    max_tokens=20\n",
    ")\n",
    "print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdacdc89",
   "metadata": {},
   "source": [
    "## 4. ReAct (Reason + Act) Prompting\n",
    "Combine reasoning and tool-use in a single prompt for agent-like behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c46852e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need to recall the author of 'Pride and Prejudice'.\n",
      "Final Answer: Jane Austen\n"
     ]
    }
   ],
   "source": [
    "react_prompt = '''You are an agent that can reason and act. Answer the question step by step, and if you need to use a tool, say \"Action: <tool> <input>\". Otherwise, say \"Final Answer: <answer>\".\n",
    "\n",
    "Question: What is the capital of France?\n",
    "Thought: I need to recall the capital of France.\n",
    "Final Answer: Paris\n",
    "\n",
    "Question: What is 5 multiplied by 7?\n",
    "Thought: I need to calculate 5 * 7.\n",
    "Final Answer: 35\n",
    "\n",
    "Question: Who wrote 'Pride and Prejudice'?\n",
    "Thought:'''\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,  # Use your deployment name\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": react_prompt}\n",
    "    ],\n",
    "    max_tokens=50\n",
    ")\n",
    "print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0d645c",
   "metadata": {},
   "source": [
    "## 5. Retrieval Augmented Generation (RAG)\n",
    "Provide retrieved context to the model for more accurate answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d43cf7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jane Austen wrote 'Pride and Prejudice'.\n"
     ]
    }
   ],
   "source": [
    "context = \"Jane Austen was an English novelist known primarily for her six major novels, including 'Pride and Prejudice'.\"\n",
    "question = \"Who wrote 'Pride and Prejudice'?\"\n",
    "rag_prompt = f\"\"\"Use the following context to answer the question.\\n\\nContext: {context}\\n\\nQuestion: {question}\\nAnswer:\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,  # Use your deployment name\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": rag_prompt}\n",
    "    ],\n",
    "    max_tokens=50\n",
    ")\n",
    "print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011c8ef0",
   "metadata": {},
   "source": [
    "## 6. Reflexion Prompting\n",
    "Reflect on and improve the model's previous answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf32015d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial answer \"Canberra\" is correct.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the capital of Australia?\"\n",
    "initial_answer = \"Canberra\"\n",
    "reflexion_prompt = f\"\"\"Question: {question}\\nInitial Answer: {initial_answer}\\nReflect on the answer above. If it is incorrect or incomplete, provide an improved answer. Otherwise, confirm it is correct.\\nReflection:\"\"\"\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,  # Use your deployment name\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": reflexion_prompt}\n",
    "    ],\n",
    "    max_tokens=50\n",
    ")\n",
    "print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998346a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Try modifying the prompts above and observe how the model's output changes. For more, see the `/theory` and `/examples` directories, and visit [Prompting Guide](https://www.promptingguide.ai/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
